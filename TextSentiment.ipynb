{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOIU3rSvGUBorog7glKorKh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xeonray-origin/TextSentimentAnalysis/blob/main/TextSentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Sentiment Analyzer"
      ],
      "metadata": {
        "id": "uun7G6oZyjV4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing dependencies[link text](https://)"
      ],
      "metadata": {
        "id": "eywg520_qlfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "collapsed": true,
        "id": "00C-6bAVqtd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textblob"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9gW9RiTJq1JB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install newspaper3k"
      ],
      "metadata": {
        "collapsed": true,
        "id": "AUbxE8P-q3-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lxml_html_clean"
      ],
      "metadata": {
        "id": "nwc4qX3xsXxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import deps"
      ],
      "metadata": {
        "id": "bi2tXGauxB5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "from newspaper import Article\n",
        "import nltk"
      ],
      "metadata": {
        "collapsed": true,
        "id": "na4yb0mQrSQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the Article URL. This is the URL of the news article you want to analyze."
      ],
      "metadata": {
        "id": "2Vi4RJGSvvw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://www.cnbc.com/2025/05/03/trump-pope-ai-image.html' # replace this with own source"
      ],
      "metadata": {
        "id": "Ve5M57E1vjQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the Article Using newspaper3k"
      ],
      "metadata": {
        "id": "dt9g5jG5v2Ik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = Article(url)"
      ],
      "metadata": {
        "id": "-3qlPajFv91Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and Parse the Article\n",
        "\n",
        "*   download() retrieves the HTML content of the article.\n",
        "*   .parse() extracts metadata and article text from the HTML."
      ],
      "metadata": {
        "id": "HFgGhjfewEkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input.download()\n",
        "input.parse()"
      ],
      "metadata": {
        "id": "aZ8X8rK0wF1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Tokenizer & Run NLP\n",
        "\n",
        "*   nltk.download('punkt_tab') is likely a typo. The correct tokenizer is 'punkt', used for sentence tokenization:\n",
        "*   .nlp() runs natural language processing tasks (e.g., keyword extraction, summary) using newspaper3k."
      ],
      "metadata": {
        "id": "s-TqEQ3lwIDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')\n",
        "input.nlp()"
      ],
      "metadata": {
        "id": "UfyzL865wiw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract Article Text"
      ],
      "metadata": {
        "id": "ZZ1-NYzSwmrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = input.text"
      ],
      "metadata": {
        "id": "6AcdNrTCwnaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyze Sentiment Using TextBlob\n",
        "\n",
        "\n",
        "*   TextBlob is a simple NLP tool for processing textual data.\n",
        "*   .sentiment.polarity returns a float in the range [-1.0, 1.0]\n",
        "*   print(sentiment) outputs the sentiment score of the article.\n",
        "\n",
        "\\> 0 indicates positive sentiment\n",
        "\n",
        "< 0 indicates negative sentiment\n",
        "\n",
        "= 0 indicates neutral sentiment"
      ],
      "metadata": {
        "id": "pTsrkVj9wpZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "textBlob = TextBlob(text)\n",
        "sentiment = textBlob.sentiment.polarity\n",
        "print(sentiment)"
      ],
      "metadata": {
        "id": "KfYJWEJdw-Lz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}